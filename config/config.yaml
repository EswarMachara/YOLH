# RefYOLO-Human Configuration
# Central configuration for dataset paths and runtime settings
# Works on: local VS Code (CPU), Lightning AI Studio (GPU)

dataset:
  # Directory containing training images
  images_dir: data/images
  # Path to COCO-format annotations JSON
  annotations_path: data/annotations.json

cache:
  # Directory for cached YOLO features
  features_dir: cache

models:
  # YOLO model paths (relative to project root)
  # These are the BASE models (pretrained) - used if yolo.fine_tune is false
  pose_model: yolo11n-pose.pt
  seg_model: yolo11n-seg.pt

# =============================================================================
# YOLO FINE-TUNING CONFIGURATION
# =============================================================================
# Fine-tune large YOLO models on the TRAIN split for improved detection.
# After fine-tuning, feature caching will use the fine-tuned weights.
yolo:
  # Large model variants for fine-tuning
  pose_model: yolo11l-pose.pt
  seg_model: yolo11l-seg.pt
  # Enable fine-tuning mode
  fine_tune: true
  # Training hyperparameters
  epochs: 30
  batch_size: 16
  img_size: 640
  learning_rate: 0.001
  weight_decay: 0.0005
  # Output directory for fine-tuned weights
  output_dir: checkpoints/yolo_finetuned
  # Paths to fine-tuned weights (used when fine_tune=true for caching/inference)
  pose_finetuned: checkpoints/yolo_finetuned/pose_best.pt
  seg_finetuned: checkpoints/yolo_finetuned/seg_best.pt

training:
  # Device: "cuda" for GPU, "cpu" for CPU-only
  device: cuda
  # Batch size for training
  batch_size: 8
  # Number of training epochs
  num_epochs: 20
  # DataLoader workers (0 for main thread)
  num_workers: 0
  # Learning rate
  learning_rate: 1.0e-4
  # Weight decay for AdamW
  weight_decay: 1.0e-4
  # Gradient clipping max norm
  grad_clip_norm: 1.0
  # Max steps per epoch (null for full dataset)
  max_steps_per_epoch: null

checkpoints:
  # Directory for saving checkpoints
  save_dir: checkpoints
  # Save checkpoint every N epochs
  save_every_epochs: 1
  # Keep best model based on margin success rate
  keep_best: true

runtime:
  # Random seed for reproducibility
  seed: 42
  # Enable deterministic mode
  deterministic: true
  # Enable mixed precision (AMP) - only on CUDA
  mixed_precision: false

# =============================================================================
# SAMPLE-LEVEL SPLITS
# =============================================================================
# Splitting is done at the SAMPLE (caption-instance) level, NOT image level.
# A sample = (image_id, caption, gt_human_index, candidate_humans)
# This is intentional for referring expression grounding.
splits:
  # Train/val/test ratios (MUST sum to exactly 1.0)
  train: 0.8
  val: 0.1
  test: 0.1
  # Seed for deterministic shuffling (separate from runtime seed)
  seed: 42

# =============================================================================
# OUTPUTS CONFIGURATION
# =============================================================================
outputs:
  # Base output directory for all artifacts
  base_dir: outputs
  # Directory for CSV logs
  logs_dir: outputs/logs
  # Directory for visualizations
  visualizations_dir: outputs/visualizations
  # Directory for plots
  plots_dir: outputs/plots
  # Directory for evaluation results
  evaluation_dir: outputs/evaluation
